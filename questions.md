# Questions

## 一、 特征工程

### 1. 为什么需要对数值类型的特征做归一化？

不同维度的数据的范围不同，所以导致收敛速度不同。而学习率的设置是相同的，但在不同数据维度的下降速度(梯度)不同，导致收敛震荡。
通过梯度下降法求解的模型通常是需要归一化的，包括`线性回归`、`逻辑回归`、`支持向量机`、`神经网络模型`；对于**决策树模型不适用**，因为节点分裂时主要依赖数据集关于特征x的信息增益比。
如下图所示的数据分布，未归一化的数据分布更加狭长，而归一化数据的梯度像碗一样，分布更加均匀。

### 2. 怎样处理类别特征？

* 序号编码(Ordinal Encoding)
用于处理类别间具有大小关系的数据，如`高>中>低`转换为`2>1>0`，仍保留大小关系

* 独热编码(One-hot Encoding)
用于处理类别之间不具有大小关系的特征，如血型，把A型转换为(1, 0, 0, 0)的稀疏矩阵。需要注意以下问题：
  
  * 节省空间，算法输入使用稀疏矩阵。
  * 配合特征选择降低维度，原因如下：
    * 高维情况下两点距离很难得到有效衡量。`K近邻`
    * 参数数量过多，容易过拟合。`逻辑回归`
    * 通常只有部分维度对模型学习有帮助。

* 二进制编码(Binary Encoding)
给每个类别赋予一个ID，得到该ID的二进制表示作为特征映射，即相应属性下只有**0/1**取值。

### 3. 什么是组合特征？如何处理高维组合特征？

#### 组合特征

在分类预测任务中中，特征通常都不是单独作用于结果的，而是把一阶离散特征两两组合构成高阶组合特征。

#### 处理高维组合特征
将两个特征合并为同一个特征，例如指定(用户ID=1并且物品ID=1)为一个属性。但容易引起组合爆炸，使参数数量过多，如用户数量为$m$，物品数量为$n$，几乎无法学习$m \times n$个参数。一种方法是将用户和物品分别用k维的向量表示，$k \ll m, k \ll n$，需要学习的参数为$m \times k + n \times k$，等价于推荐系统的矩阵分解。

#### *矩阵分解

### 4. 怎样有效地找到组合特征？

基于决策树的方法，可以使用集成学习算法中的**梯度提升决策树(GBDT)**，找出特征的有效分裂点，和与其他特征之间的关系。

### 5. 有哪些文本表示模型？它们各有什么优缺点？

* 词袋模型(BOW)和N-gram模型
  词袋模型忽略了词出现的顺序，输入的文章转换为一个长向量，每一维代表一个单词，该维对应的权重反映了这个词在原文章中的重要程度，通常用TF-IDF来计算。
  $$
    TF-IDF(t, d) = TF(t, d) \times IDF(t) \\
    IDF(t) = log\frac{DocumentsCount}{包含单词t的文章总数+1}
  $$
  N-gram模型可以将多个单词连起来的固定搭配作为一维特征进行输入，如("自然", "语言", "处理")的合并单独作为一个特征(Word Piece)，英文有时还需要进行词干(word stemming)抽取处理。
* 主题模型
  将大量文章进行无监督地聚类学习，发现代表性的主题和每个主题上面有代表性的词，从而计算出每篇文章的主题分布，主要方法有LDA(隐狄利克雷模型)。
* 词嵌入与深度学习
  WordEmbedding，是一种概率语言模型，能够将词映射到低维空间(通常50～300)。由于传统的模型更加稀疏，深度学习无法很好地处理这种数据，word2vec是谷歌的一个词嵌入实现，将深度学习引入NLP领域成为了可能。

### 6. Word2vec是如何工作的？它和LDA有什么区别和联系？

## 二、 模型评估

评估指标是指导模型优化的重要因素，能够发现模型问题。如果指标选的不好，极其容易得出错误结论。

### 1. 准确率的局限性

准确率的定义：
$$Accuracy = \frac{n_{correct}}{n_{total}}$$

它是比较简单直观的评价指标，但是当负样本的比例较高时(如99%)，即使分类器把所有样本都预测为负样本也可以获得99%的准确率，所以不适用于样本比例**非常**不均衡时。

### 2. 精确率与召回率的权衡

* 精确率Precision，指分类正确的正样本个数占**分类器判定为正样本**的样本的个数的比例。
* 召回率Recall，指分类正确的正样本个数占**真正的正样本**个数的比例。

精确率代表分类器在有把握的情况下，分类正确的比例，如果过于保守，就会漏掉许多实际为正例的样本，所以需要权衡精确率和召回率。

* P-R曲线，横轴是召回率，纵轴是精确率。每个点都代表某一阈值下的精确率和召回率。
* F1 score是对精确率和召回率的调和平均值：
  $$F1 = \frac{ 2 \times precision \times recall } { precision + recall}.$$

### 3. 平方根误差的问题

RMSE，用来衡量**回归**的模型的效果。
$$RMSE = \sqrt{ \frac{ \sum_{i=1}^{n}(y_i - \hat{y_i})^2 }{n} }.$$

其中，$\hat{y_i}$是第$i$个样本的预测值。
当存在离群点时，偏离程度很大的情况下，尽管离群点数量很少，也会让RMSE指标变得很差，如流量突变。
解决方案：

1. 去除认为是噪声点的离群点.
2. 将离群点预测机制融合如模型中.
3. 找一个更好得指标，如平均绝对百分比误差(Mean Absolute Percent Error, MAPE)，相当于误差归一化，降低了绝对误差的影响。定义为：
  $$MAPE = \sum_{i=1}^{n}\left| \frac{y_i - \hat{y_i} }{ y_i } \times \frac{100}{n} \right|$$

### 4. ROC曲线

#### 4.

## TODO LIST

* [ ] 添加图片
* [ ] 完成所有问题输入及解答
* [ ] pandas、sklearn示例